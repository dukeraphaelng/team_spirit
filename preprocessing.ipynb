{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 217,
=======
   "execution_count": 19,
>>>>>>> 6ea7ca8 (one-hot)
=======
   "execution_count": 19,
>>>>>>> 6ea7ca8 (one-hot)
   "id": "e2adbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from data_io import get_book\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 218,
   "id": "6e26aaea",
=======
   "execution_count": 20,
   "id": "e132fea4",
>>>>>>> 6ea7ca8 (one-hot)
=======
   "execution_count": 20,
   "id": "e132fea4",
>>>>>>> 6ea7ca8 (one-hot)
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_to_onehop(df):\n",
    "    s = pd.Series(list(df['author']))\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    one_hot = pd.get_dummies(s).values\n",
    "    pd.get_dummies(s).values\n",
    "    df = df.join(one_hot)\n",
    "    return df\n"
=======
    "    one_hot = pd.get_dummies(s)\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    return df"
>>>>>>> 6ea7ca8 (one-hot)
=======
    "    one_hot = pd.get_dummies(s)\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    return df"
>>>>>>> 6ea7ca8 (one-hot)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 219,
=======
   "execution_count": 21,
>>>>>>> 6ea7ca8 (one-hot)
=======
   "execution_count": 21,
>>>>>>> 6ea7ca8 (one-hot)
   "id": "0938f3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 219,
=======
     "execution_count": 21,
>>>>>>> 6ea7ca8 (one-hot)
=======
     "execution_count": 21,
>>>>>>> 6ea7ca8 (one-hot)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_filename = 'metadata.csv'\n",
    "counts_dirname = 'counts'\n",
    "tokens_dirname = 'tokens'\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_filename)\n",
    "\n",
    "filtered_df = metadata_df[(metadata_df.language == \"['en']\") & (metadata_df.type == 'Text')]\n",
    "\n",
    "SELECTED_COLUMNS = ['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath']\n",
    "filtered_df = filtered_df.dropna(subset=SELECTED_COLUMNS)\n",
    "filtered_df = filtered_df[SELECTED_COLUMNS]\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "author_count = filtered_df['author'].value_counts()\n",
    "many_works_author = author_count[author_count >= 10]\n",
    "filtered_df = filtered_df[filtered_df.author.isin(many_works_author.index.to_numpy())].reset_index()\n",
    "\n",
    "'PG8700' in filtered_df.id"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 220,
=======
   "execution_count": 22,
>>>>>>> 6ea7ca8 (one-hot)
=======
   "execution_count": 22,
>>>>>>> 6ea7ca8 (one-hot)
   "id": "df4ee5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[220], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     val_ids\u001b[39m.\u001b[39mappend(val_id)\n\u001b[1;32m     19\u001b[0m \u001b[39m# one hot\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m filtered_df \u001b[39m=\u001b[39m author_to_onehop(filtered_df)\n\u001b[1;32m     22\u001b[0m train_df \u001b[39m=\u001b[39m filtered_df[filtered_df\u001b[39m.\u001b[39mid\u001b[39m.\u001b[39misin(train_ids)]\n\u001b[1;32m     23\u001b[0m test_df \u001b[39m=\u001b[39m filtered_df[filtered_df\u001b[39m.\u001b[39mid\u001b[39m.\u001b[39misin(test_ids)]\n",
      "Cell \u001b[0;32mIn[218], line 5\u001b[0m, in \u001b[0;36mauthor_to_onehop\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m one_hot \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(s)\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(pd\u001b[39m.\u001b[39mget_dummies(s)\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m----> 5\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mjoin(one_hot)\n\u001b[1;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:9976\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[1;32m   9814\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9815\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[DataFrame \u001b[39m|\u001b[39m Series],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9821\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9822\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9824\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[1;32m   9825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9974\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[1;32m   9975\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9976\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[1;32m   9977\u001b[0m         other,\n\u001b[1;32m   9978\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9979\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9980\u001b[0m         lsuffix\u001b[39m=\u001b[39;49mlsuffix,\n\u001b[1;32m   9981\u001b[0m         rsuffix\u001b[39m=\u001b[39;49mrsuffix,\n\u001b[1;32m   9982\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9983\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   9984\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:10043\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m  10037\u001b[0m \u001b[39m# Mypy thinks the RHS is a\u001b[39;00m\n\u001b[1;32m  10038\u001b[0m \u001b[39m# \"Union[DataFrame, Series, Iterable[Union[DataFrame, Series]]]\" whereas\u001b[39;00m\n\u001b[1;32m  10039\u001b[0m \u001b[39m# the LHS is an \"Iterable[DataFrame]\", but in reality both types are\u001b[39;00m\n\u001b[1;32m  10040\u001b[0m \u001b[39m# \"Iterable[Union[DataFrame, Series]]\" due to the if statements\u001b[39;00m\n\u001b[1;32m  10041\u001b[0m frames \u001b[39m=\u001b[39m [cast(\u001b[39m\"\u001b[39m\u001b[39mDataFrame | Series\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m)] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(other)\n\u001b[0;32m> 10043\u001b[0m can_concat \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mis_unique \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m frames)\n\u001b[1;32m  10045\u001b[0m \u001b[39m# join indexes only using concat\u001b[39;00m\n\u001b[1;32m  10046\u001b[0m \u001b[39mif\u001b[39;00m can_concat:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:10043\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m  10037\u001b[0m \u001b[39m# Mypy thinks the RHS is a\u001b[39;00m\n\u001b[1;32m  10038\u001b[0m \u001b[39m# \"Union[DataFrame, Series, Iterable[Union[DataFrame, Series]]]\" whereas\u001b[39;00m\n\u001b[1;32m  10039\u001b[0m \u001b[39m# the LHS is an \"Iterable[DataFrame]\", but in reality both types are\u001b[39;00m\n\u001b[1;32m  10040\u001b[0m \u001b[39m# \"Iterable[Union[DataFrame, Series]]\" due to the if statements\u001b[39;00m\n\u001b[1;32m  10041\u001b[0m frames \u001b[39m=\u001b[39m [cast(\u001b[39m\"\u001b[39m\u001b[39mDataFrame | Series\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m)] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(other)\n\u001b[0;32m> 10043\u001b[0m can_concat \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(df\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39mis_unique \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m frames)\n\u001b[1;32m  10045\u001b[0m \u001b[39m# join indexes only using concat\u001b[39;00m\n\u001b[1;32m  10046\u001b[0m \u001b[39mif\u001b[39;00m can_concat:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
=======
=======
>>>>>>> 6ea7ca8 (one-hot)
      "Index(['text', 'Abbott, Eleanor Hallowell', 'Abbott, Jacob',\n",
      "       'Abbott, John S. C. (John Stevens Cabot)', 'Adams, Samuel Hopkins',\n",
      "       'Aimard, Gustave', 'Ainsworth, William Harrison', 'Alcott, Louisa May',\n",
      "       'Aldrich, Thomas Bailey', 'Alger, Horatio, Jr.',\n",
      "       ...\n",
      "       'Woolson, Constance Fenimore', 'Wordsworth, William',\n",
      "       'Wright, Harold Bell', 'Xenophon', 'Yeats, W. B. (William Butler)',\n",
      "       'Yonge, Charlotte M. (Charlotte Mary)', 'Young, Filson',\n",
      "       'Zangwill, Israel', 'Zola, Émile', '`Abdu'l-Bahá'],\n",
      "      dtype='object', length=634)\n",
      "Index(['text', 'Abbott, Eleanor Hallowell', 'Abbott, Jacob',\n",
      "       'Abbott, John S. C. (John Stevens Cabot)', 'Adams, Samuel Hopkins',\n",
      "       'Aimard, Gustave', 'Ainsworth, William Harrison', 'Alcott, Louisa May',\n",
      "       'Aldrich, Thomas Bailey', 'Alger, Horatio, Jr.',\n",
      "       ...\n",
      "       'Woolson, Constance Fenimore', 'Wordsworth, William',\n",
      "       'Wright, Harold Bell', 'Xenophon', 'Yeats, W. B. (William Butler)',\n",
      "       'Yonge, Charlotte M. (Charlotte Mary)', 'Young, Filson',\n",
      "       'Zangwill, Israel', 'Zola, Émile', '`Abdu'l-Bahá'],\n",
      "      dtype='object', length=634)\n",
      "Index(['text', 'Abbott, Eleanor Hallowell', 'Abbott, Jacob',\n",
      "       'Abbott, John S. C. (John Stevens Cabot)', 'Adams, Samuel Hopkins',\n",
      "       'Aimard, Gustave', 'Ainsworth, William Harrison', 'Alcott, Louisa May',\n",
      "       'Aldrich, Thomas Bailey', 'Alger, Horatio, Jr.',\n",
      "       ...\n",
      "       'Woolson, Constance Fenimore', 'Wordsworth, William',\n",
      "       'Wright, Harold Bell', 'Xenophon', 'Yeats, W. B. (William Butler)',\n",
      "       'Yonge, Charlotte M. (Charlotte Mary)', 'Young, Filson',\n",
      "       'Zangwill, Israel', 'Zola, Émile', '`Abdu'l-Bahá'],\n",
      "      dtype='object', length=634)\n"
<<<<<<< HEAD
>>>>>>> 6ea7ca8 (one-hot)
=======
>>>>>>> 6ea7ca8 (one-hot)
     ]
    }
   ],
   "source": [
    "# filtered_df = filtered_df.sample(n=50, random_state=2).reset_index()\n",
    "\n",
    "sampled_authors = filtered_df.author.sample(n=50, random_state=1)\n",
    "\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "val_ids = []\n",
    "\n",
    "for author in sampled_authors:\n",
    "    works = filtered_df[filtered_df.author == author].sample(n=3, random_state=1)\n",
    "    train_id, test_id, val_id = works.id\n",
    "    \n",
    "    # Does not check if this file exists and is valid\n",
    "    \n",
    "    train_ids.append(train_id)\n",
    "    test_ids.append(test_id)\n",
    "    val_ids.append(val_id)\n",
    "\n",
    "# one hot\n",
    "filtered_df = author_to_onehop(filtered_df)\n",
    "\n",
    "train_df = filtered_df[filtered_df.id.isin(train_ids)]\n",
    "test_df = filtered_df[filtered_df.id.isin(test_ids)]\n",
    "val_df = filtered_df[filtered_df.id.isin(val_ids)]\n",
    "\n",
    "df_arrs = []\n",
<<<<<<< HEAD
=======
    "for df in [train_df, test_df, val_df]:\n",
<<<<<<< HEAD
>>>>>>> 6ea7ca8 (one-hot)
=======
>>>>>>> 6ea7ca8 (one-hot)
    "\n",
    "\n",
    "for df in [train_df, test_df, val_df]:\n",
    "    docs = []\n",
    "    docs_unavail_pg_ids = []\n",
    "    for pg_id in df.id:    \n",
    "        try:\n",
    "            tokens = get_book(pg_id, os.path.join(tokens_dirname), level='tokens')[0:512]\n",
    "            doc = ' '.join(tokens)\n",
    "            docs.append(doc)\n",
    "        except:\n",
    "            docs_unavail_pg_ids.append(pg_id)\n",
    "\n",
    "    df = df[~df.id.isin(docs_unavail_pg_ids)].reset_index()\n",
    "    df = df.drop(columns=['level_0', 'index', 'id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath'])\n",
    "    df.insert(0, 'text', docs, True)\n",
    "    print(df.columns)\n",
    "    df_arrs.append(df)\n",
    "\n",
    "train_df, test_df, val_df = df_arrs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> 6ea7ca8 (one-hot)
=======
   "execution_count": 23,
>>>>>>> 6ea7ca8 (one-hot)
   "id": "0540bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)\n",
    "val_df.to_csv('val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
